{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "from textdataset_generation import TextDataset\n",
    "from rnn import RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the desired parts of the books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "def preprocessing(filepath, text, end=False):\n",
    "    if 'austen' in filepath:\n",
    "        start = text.find(\"Chapter I.]\")\n",
    "\n",
    "    elif 'dostoyevsky' in filepath:\n",
    "        start = text.find(\"CHAPTER I\")\n",
    "\n",
    "    elif 'god' in filepath:\n",
    "        start = text.find(\"1:1\")\n",
    "\n",
    "    elif 'kafka' in filepath:\n",
    "        start = text.find(\"Chapter One\")\n",
    "\n",
    "    elif 'shelley' in filepath:\n",
    "        start = text.find(\"_To\")\n",
    "\n",
    "    elif 'tolstoy' in filepath:\n",
    "        start = text.find(\"Chapter 1\")\n",
    "\n",
    "    elif 'sturluson' in filepath:\n",
    "        start = text.find(\"PREFACE OF SNORRE STURLASON.\")\n",
    "        \n",
    "    elif 'cervantes' in filepath:\n",
    "        start = text.find(\"Idle reader:\")\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"This book is not in our library!\")\n",
    "    \n",
    "    if not end:\n",
    "        end = text.find(\"*** END\")\n",
    "   \n",
    "    return text[start:end]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class implementation of the code outlined in Rasckha: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerationModel:\n",
    "    def __init__(self, \n",
    "                 filepath, \n",
    "                 device='cpu',\n",
    "                 seq_length=40, \n",
    "                 embed_dim=256, \n",
    "                 rnn_hidden_size=512, \n",
    "                 batch_size=64, \n",
    "                 lr=0.001\n",
    "                 ):\n",
    "        self.device = device\n",
    "        self.seq_length = seq_length\n",
    "        self.embed_dim = embed_dim\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.lr=lr\n",
    "\n",
    "        # Preprocess text - pick ou the relevant part of the text\n",
    "        self.encode_text(filepath)\n",
    "        \n",
    "        # Create dataset and dataloader\n",
    "        self.create_dataloader()\n",
    "\n",
    "        # Initialize model, loss function, and optimizer\n",
    "        self.initialize_model()\n",
    "\n",
    "    def encode_text(self, filepath):\n",
    "        \"\"\"\n",
    "        Reads in the given file and picks out the relevant parts of the text given\n",
    "        start and stop defined in `preprocessing`.\n",
    "        Creates a set of the characters and a dictionary with correspondence between\n",
    "        charcter and an integer and uses this to encode the text from strings to ints.\n",
    "        Splits the encoded text into chunks. \n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        filepath (str)\n",
    "            Path to file one wishes to read in and encode\n",
    "\n",
    "        \"\"\"\n",
    "        with open(filepath, 'r', encoding=\"utf8\") as fp:\n",
    "            text=fp.read()\n",
    "\n",
    "        text = preprocessing(filepath, text)\n",
    "        char_set = set(text)\n",
    "\n",
    "        # create dictionary and encode text\n",
    "        self.char_array = np.array(sorted(char_set))\n",
    "        self.char2int = {ch: i for i, ch in enumerate(self.char_array)}\n",
    "        text_encoded = np.array([self.char2int[ch] for ch in text], dtype=np.int32)\n",
    "        \n",
    "        # split text into chunks\n",
    "        chunk_size = self.seq_length + 1\n",
    "        self.text_chunks = [text_encoded[i:i + chunk_size] for i in range(len(text_encoded) - chunk_size + 1)]\n",
    "\n",
    "    def create_dataloader(self):\n",
    "        \"\"\"\n",
    "        Create dataset and dataloader of text chunks.\n",
    "        \"\"\"\n",
    "        seq_dataset = TextDataset(torch.tensor(np.array(self.text_chunks)))\n",
    "        self.seq_dl = DataLoader(seq_dataset, batch_size=self.batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    def initialize_model(self):\n",
    "        \"\"\"\n",
    "        Initializing the model by setting up the neural net with its nodes, and\n",
    "        defining the loss function and the optimizer.\n",
    "        \"\"\"\n",
    "        self.vocab_size = len(self.char_array)\n",
    "        self.model = RNN(self.vocab_size, self.embed_dim, self.rnn_hidden_size)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "    \n",
    "    def train_model(self, num_epochs=100):\n",
    "        \"\"\" \n",
    "        Train the model given the model paramters specified in \n",
    "        `initialize_model` for a number of epochs. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_epochs (int):\n",
    "            Number of training epochs. Default is 100.\n",
    "        \"\"\"\n",
    "        torch.manual_seed(1)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            hidden, cell = self.model.init_hidden(self.batch_size)\n",
    "            seq_batch, target_batch = next(iter(self.seq_dl))\n",
    "            seq_batch, target_batch = seq_batch.to(self.device), target_batch.to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = 0\n",
    "            for c in range(self.seq_length):\n",
    "                pred, hidden, cell = self.model(seq_batch[:, c], hidden, cell)\n",
    "                loss += self.loss_fn(pred, target_batch[:, c])\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            loss = loss.item() / self.seq_length\n",
    "\n",
    "            if epoch % 500 == 0:\n",
    "                print(f'Epoch {epoch} loss: {loss:.4f}')\n",
    "\n",
    "    def save_model(self, path):\n",
    "        \"\"\" \n",
    "        Saves the model with the trained weights \n",
    "        to the specified location.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        path (str)\n",
    "            Filepath to desired saving location with name of model.\n",
    "        \"\"\"\n",
    "        torch.save(self.model, path)\n",
    "\n",
    "    def sample(self, starting_str, len_generated_text=500, scale_factor=2.0):\n",
    "        \"\"\"\" \n",
    "        Generate a sample of text that is (ideally) similar to the training\n",
    "        inputs.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        starting_str (str)\n",
    "            String starting out the text generation.ipynb\n",
    "\n",
    "        len_generated_text (int)\n",
    "            Length of generated text. Default is 500.\n",
    "\n",
    "        scale_factor (float)\n",
    "            Controls the level of randomness of the text generation. Default is 2.0.\n",
    "        \"\"\"\n",
    "        encoded_input = torch.tensor([self.char2int[s] for s in starting_str])\n",
    "        encoded_input = torch.reshape(encoded_input, (1, -1))\n",
    "\n",
    "        generated_str = starting_str\n",
    "\n",
    "        self.model.eval()\n",
    "        hidden, cell = self.model.init_hidden(1)\n",
    "        hidden, cell = hidden.to(self.device), cell.to(self.device)\n",
    "        encoded_input = encoded_input.to(self.device)\n",
    "\n",
    "        for c in range(len(starting_str) - 1):\n",
    "            _, hidden, cell = self.model(encoded_input[:, c].view(1), hidden, cell)\n",
    "\n",
    "        last_char = encoded_input[:, -1]\n",
    "        for i in range(len_generated_text):\n",
    "            logits, hidden, cell = self.model(last_char.view(1), hidden, cell)\n",
    "            logits = torch.squeeze(logits, 0)\n",
    "            scaled_logits = logits * scale_factor\n",
    "            m = Categorical(logits=scaled_logits)\n",
    "            last_char = m.sample()\n",
    "            generated_str += str(self.char_array[last_char])\n",
    "\n",
    "        return generated_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating an instance of the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 4.4536\n",
      "Victore in the part of his convinces delighted him to her talked her as such all the scarcely and make intemption the had not concere concent of seelings at the subject, and she was not be the event that I have been her feel that her something and they concending her the would accontent the former of Mr. Bennet which must attention of compoming a seld in the part, and been me, at it is not be mether in the subject of her\n",
      "in my deserved and the should not such a sention of all the was mention you are o\n"
     ]
    }
   ],
   "source": [
    "model = TextGenerationModel(filepath='../Texts/austen.txt', \n",
    "                            seq_length=40, \n",
    "                            embed_dim=256, \n",
    "                            rnn_hidden_size=512, \n",
    "                            batch_size=64, \n",
    "                            device='cpu')\n",
    "\n",
    "model.train_model(num_epochs=10_000)\n",
    "\n",
    "# save model\n",
    "#model.save_model('austen_generator.pt')\n",
    "\n",
    "# Generate new text\n",
    "generated_text = model.sample(starting_str='Darcy', len_generated_text=500)\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYS-STK3155",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
