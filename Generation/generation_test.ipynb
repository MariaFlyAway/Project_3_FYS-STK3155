{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "This file includes code which classifies text chunks as (Austen, Shelly, Kafka, Tolstoy or Dostoyevsky).\n",
    "The training data is text chunks from their respective works _Pride and predjudice_, _Frankenstein_, _The trial_, _Anna Karenina_ and _Crime and punishment_. We obtain the texts from the Gutenberg Project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "from textdataset import TextDataset\n",
    "from rnn import RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "def preprocessing(filepath, text, end=False):\n",
    "    \"\"\" \n",
    "    Retrieve the relevant part of the text\n",
    "    \"\"\"\n",
    "    if 'austen' in filepath:\n",
    "        start = text.find(\"Chapter I.]\")\n",
    "    elif 'dostoyevsky' in filepath:\n",
    "        start = text.find(\"CHAPTER I\")\n",
    "\n",
    "    elif 'god' in filepath:\n",
    "        start = text.find(\"1:1\")\n",
    "        end = text.find(\"in the sight of all Israel.\") # Only old testament\n",
    "\n",
    "    elif 'kafka' in filepath:\n",
    "        start = text.find(\"Chapter One\")\n",
    "\n",
    "    elif 'shelley' in filepath:\n",
    "        start = text.find(\"_To\")\n",
    "\n",
    "    elif 'tolstoy' in filepath:\n",
    "        start = text.find(\"Chapter 1\")\n",
    "\n",
    "    elif 'sturluson' in filepath:\n",
    "        start = text.find(\"PREFACE OF SNORRE STURLASON.\")\n",
    "        end = text.find(\"SAGA OF HARALD HARDRADE.\") # Only Heimskringla\n",
    "        \n",
    "    elif 'cervantes' in filepath:\n",
    "        start = text.find(\"Idle reader:\")\n",
    "        end = text.find(\"Forse altro cantera con miglior plettro.\") # Only Volume I\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"This book is not in our library!\")\n",
    "    \n",
    "    if not end:\n",
    "        end = text.find(\"*** END\")\n",
    "\n",
    "    return text[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    with open(filepath, encoding='utf-8') as infile:\n",
    "        text = preprocessing(filepath, infile.read()) # list of words, preprocessed\n",
    "\n",
    "    return text, set(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\Texts\\dostoyevsky\n",
      "Total Length: 1130503\n",
      "Unique Characters: 91\n"
     ]
    }
   ],
   "source": [
    "folder = \"..\"\n",
    "subfolder = \"Texts\"\n",
    "# filenames = ['austen', 'dostoyevsky', 'god', 'cervantes', 'sturluson']\n",
    "filenames = ['dostoyevsky']\n",
    "filepaths = [os.path.join(folder, subfolder, filename) for filename in filenames]\n",
    "\n",
    "# Uncomment to embed\n",
    "for filepath in filepaths:\n",
    "    print(filepath)\n",
    "    text, char_set = read_file(filepath+'.txt') \n",
    "\n",
    "\n",
    "print('Total Length:', len(text))\n",
    "print('Unique Characters:', len(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_sorted = sorted(char_set)\n",
    "char2int = {ch:i for i,ch in enumerate(chars_sorted)}\n",
    "char_array = np.array(chars_sorted)\n",
    "\n",
    "text_encoded = np.array(\n",
    "    [char2int[ch] for ch in text],\n",
    "    dtype=np.int32)\n",
    "\n",
    "seq_length = 40         # sequence length\n",
    "chunk_size = seq_length + 1\n",
    "text_chunks = [text_encoded[i:i+chunk_size]\n",
    "               for i in range(len(text_encoded)-chunk_size+1)]\n",
    "\n",
    "seq_dataset = TextDataset(torch.tensor(np.array(text_chunks)))\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "batch_size = 64\n",
    "torch.manual_seed(1)\n",
    "seq_dl = DataLoader(seq_dataset, batch_size=batch_size, \n",
    "                    shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(char_array)\n",
    "embed_dim = 256\n",
    "rnn_hidden_size = 512\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size)\n",
    "\n",
    "# optimizer and loss\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 4.5106\n",
      "Epoch 500 loss: 1.5498\n",
      "Epoch 1000 loss: 1.4512\n",
      "Epoch 1500 loss: 1.3801\n",
      "Epoch 2000 loss: 1.3268\n",
      "Epoch 2500 loss: 1.3032\n",
      "Epoch 3000 loss: 1.2754\n",
      "Epoch 3500 loss: 1.1833\n",
      "Epoch 4000 loss: 1.1894\n",
      "Epoch 4500 loss: 1.2225\n",
      "Epoch 5000 loss: 1.1875\n",
      "Epoch 5500 loss: 1.1548\n",
      "Epoch 6000 loss: 1.1714\n",
      "Epoch 6500 loss: 1.1770\n",
      "Epoch 7000 loss: 1.1214\n",
      "Epoch 7500 loss: 1.1169\n",
      "Epoch 8000 loss: 1.1575\n",
      "Epoch 8500 loss: 1.1189\n",
      "Epoch 9000 loss: 1.1035\n",
      "Epoch 9500 loss: 1.1140\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10_000\n",
    "torch.manual_seed(1)\n",
    "\n",
    "def training_model():\n",
    "    for epoch in range(num_epochs):\n",
    "        hidden, cell = model.init_hidden(batch_size)\n",
    "        seq_batch, target_batch = next(iter(seq_dl))            \n",
    "        seq_batch = seq_batch.to(device)\n",
    "        target_batch = target_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = 0\n",
    "        for c in range(seq_length):\n",
    "            pred, hidden, cell = model(seq_batch[:, c], hidden, cell)\n",
    "            loss += loss_fn(pred, target_batch[:, c])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss = loss.item() / seq_length\n",
    "        if epoch % 500 == 0:\n",
    "            print(f'Epoch {epoch} loss: {loss:.4f}')\n",
    "\n",
    "training_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'dostoyevsky_generator.pt'\n",
    "torch.save(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criminals laughing at the business is the room was a ragged to him on the stairs. “That’s not worth things, I am afraid of it. I saw you that I am a special fools,’ says he is not at the point of it. If I were to pay him and so on. Do you suppose I shall be seen in the contrary!”\n",
      "\n",
      "“A lie--there is no one was sentinually as I can always find out for your sister and the workmen and put the whole street to the stairs--all his words.\n",
      "\n",
      "“It’s nothing about it all too, I want to take the book it is!” He went o\n"
     ]
    }
   ],
   "source": [
    "def sample(model, starting_str, \n",
    "           len_generated_text=500, \n",
    "           scale_factor=2.0):\n",
    "\n",
    "    encoded_input = torch.tensor([char2int[s] for s in starting_str])\n",
    "    encoded_input = torch.reshape(encoded_input, (1, -1))\n",
    "\n",
    "    generated_str = starting_str\n",
    "\n",
    "    model.eval()\n",
    "    hidden, cell = model.init_hidden(1)\n",
    "    hidden = hidden.to('cpu')\n",
    "    cell = cell.to('cpu')\n",
    "    for c in range(len(starting_str)-1):\n",
    "        _, hidden, cell = model(encoded_input[:, c].view(1), hidden, cell) \n",
    "    \n",
    "    last_char = encoded_input[:, -1]\n",
    "    for i in range(len_generated_text):\n",
    "        logits, hidden, cell = model(last_char.view(1), hidden, cell) \n",
    "        logits = torch.squeeze(logits, 0)\n",
    "        scaled_logits = logits * scale_factor\n",
    "        m = Categorical(logits=scaled_logits)\n",
    "        last_char = m.sample()\n",
    "        generated_str += str(char_array[last_char])\n",
    "        \n",
    "    return generated_str\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model.to('cpu')\n",
    "print(sample(model, starting_str='criminal'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYS-STK3155",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
